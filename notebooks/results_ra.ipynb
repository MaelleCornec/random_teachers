{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from itertools import takewhile, islice\n",
    "\n",
    "\n",
    "from typing import Dict, Iterable, Any\n",
    "from numbers import Number\n",
    "\n",
    "from wandb.apis.public import Run\n",
    "Runs = Iterable[Run]\n",
    "api = wandb.Api(timeout=19)\n",
    "\n",
    "import dinopl.utils as U\n",
    "\n",
    "#sns.set_theme()\n",
    "#sns.set_theme(context='paper', font_scale=0.5)\n",
    "#sns.set_style()\n",
    "\n",
    "\n",
    "from tueplots import bundles, axes, figsizes, fonts, fontsizes\n",
    "tue_params = bundles.icml2022(usetex=False, family='sans-serif') #sans-serif\n",
    "tue_params.update(bundles.fontsizes.icml2022(default_smaller=1))\n",
    "tue_params.update(figsizes.icml2022_half(tight_layout=True, pad_inches=0)) \n",
    "tue_params.update(axes.lines(base_width=0.25))\n",
    "tue_params.update(axes.legend(frameon=True, fancybox=False))\n",
    "#sns.set_style(style='darkgrid', rc=tue_params)\n",
    "plt.rcParams.update(tue_params)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "matplotlib.rcParams['text.latex.preamble'] = matplotlib.rcParams['text.latex.preamble'] + r\" \\usepackage{amsmath, amssymb}\"\n",
    "\n",
    "\n",
    "# Use latest verion of matplotlib-inline to avoid jupyter notebook bug:\n",
    "#https://github.com/matplotlib/matplotlib/issues/9217\n",
    "#https://github.com/ipython/ipykernel/issues/267"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize, BoundaryNorm, Colormap\n",
    "from warnings import warn\n",
    "\n",
    "def alphanumsort(keys, reverse_sort=False):\n",
    "    str_keys = [k for k in keys if isinstance(k, str)]\n",
    "    nbr_keys = [k for k in keys if isinstance(k, Number)]\n",
    "    sorted_keys = list(sorted(nbr_keys, reverse=reverse_sort))\n",
    "    sorted_keys += list(sorted(str_keys, reverse=reverse_sort))\n",
    "    return sorted_keys\n",
    "\n",
    "def get_run_attr(run, key:str):\n",
    "    if key.startswith('config.'):\n",
    "        key = key[len('config.'):] # remove config.\n",
    "        return run.config[key]\n",
    "    if key.startswith('summary.'):\n",
    "        key = key[len('summary.'):] # remove summary.\n",
    "        return run.summary[key]\n",
    "    if key.startswith('dino_config.'):\n",
    "        key = key[len('dino_config.'):] # remove dino_config.\n",
    "        return run.config['dino_config'][key]\n",
    "\n",
    "def plot_agg(runs:Runs, group_by:str, metric:str, xmetric:str=None, labels:list=None, \n",
    "                group_keys=None, reverse_sort=False, filter:dict={}, colors:Colormap=None, \n",
    "                center='mean', spread='std', center_kwargs={}, spread_kwargs={}, plot_kwargs={}, \n",
    "                scan_step:int=None, max_step=None, ema_alpha:float=0., summarize='max', slice2summarize=slice(1, None),  ax=None,\n",
    "                ):\n",
    "    center_kwargs = plot_kwargs | center_kwargs      # use plot_kwargs as default for center_kwargs\n",
    "    spread_kwargs = plot_kwargs | spread_kwargs      # use plot_kwargs as default for spread_kwargs\n",
    "    spread_kwargs = dict(alpha=0.15) | spread_kwargs # set default alpha for spread\n",
    "\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "    groups:Dict[Any, Iterable[Run]] = {}\n",
    "    for run in runs: \n",
    "        #if any([run.config[name] != value for name, value in filter.items()]):\n",
    "        #    continue\n",
    "\n",
    "        if any([get_run_attr(run, name) != value for name, value in filter.items()]):\n",
    "            continue\n",
    "\n",
    "        group_val = get_run_attr(run, group_by)\n",
    "        #if group_by.startswith('dino_config.'): \n",
    "        #    group_val = run.config['dino_config'][group_by[len('dino_config.'):]]\n",
    "        #else:\n",
    "        #    group_val = run.config[group_by]\n",
    "\n",
    "        # group by by config\n",
    "        if group_val not in groups.keys():\n",
    "            groups[group_val] = []\n",
    "        groups[group_val].append(run)\n",
    "\n",
    "    if group_keys is None:\n",
    "        group_keys = alphanumsort(groups.keys())\n",
    "    \n",
    "    if len(groups.items()) == 0:\n",
    "        warn('No runs to plot.')\n",
    "        return None\n",
    "\n",
    "    # make labels\n",
    "    if labels is None:\n",
    "        labels = group_keys\n",
    "    if not isinstance(labels, list):\n",
    "        labels = [labels] * len(group_keys)\n",
    "    if len(labels) != len(group_keys):\n",
    "        raise ValueError('Provided labels are not of same length as group keys.')\n",
    "    \n",
    "    # make colors\n",
    "    if colors is None: # set default colorcycle\n",
    "        colors = list(cm.tab10.colors)\n",
    "\n",
    "    if isinstance(colors, (tuple, str, float)):\n",
    "        colors = [colors] * len(group_keys)\n",
    "    elif isinstance(colors, Iterable):\n",
    "        cmapper = cycler(colors=colors)\n",
    "        colors = [elem['c'] for _, elem in zip(group_keys, cycler(c=colors))]\n",
    "    elif isinstance(colors, Colormap):\n",
    "        color_keys = group_keys\n",
    "        if not all(isinstance(k, (float, int)) for k in color_keys):\n",
    "            color_keys = range(len(group_keys))\n",
    "        #norm = Normalize(group_keys)              # linearly \n",
    "        #norm = BoundaryNorm(sorted(group_keys), colors.N, extend='max')    # discrete sorted numeric values\n",
    "        norm = BoundaryNorm(sorted(color_keys), colors.N, extend='max')    # discrete sorted numeric values\n",
    "        cmapper = cm.ScalarMappable(norm=norm, cmap=colors)\n",
    "        colors = map(cmapper.to_rgba, color_keys)\n",
    "\n",
    "    # iterate through groups\n",
    "    summary = dict()\n",
    "    n_aggregates = dict()\n",
    "    for group_key, label, color in tqdm(list(zip(group_keys, labels, colors))):\n",
    "        hists, hists_xs = [], [] # gather histories of runs in group\n",
    "        for run in groups[group_key]:\n",
    "            hist:pd.DataFrame = run.history(keys=[metric]+([] if xmetric is None else [xmetric]))\n",
    "\n",
    "            if scan_step is not None:\n",
    "                scan = run.scan_history(keys=[metric, 'trainer/global_step']+([] if xmetric is None else [xmetric]))\n",
    "                if hist.empty:\n",
    "                    continue\n",
    "                hist = pd.DataFrame(islice(scan, 0, max_step, scan_step), dtype=float) # run.summary['trainer/global_step'] // scan_samples\n",
    "                if xmetric == 'epoch':\n",
    "                    hist[xmetric] = hist['trainer/global_step'] * hist[xmetric].iloc[-1] / hist['trainer/global_step'].iloc[-1]\n",
    "                    hist[xmetric] = hist[xmetric].fillna(0.0)\n",
    "            \n",
    "                # sort values and interpolate xmetric\n",
    "                hist = hist.sort_values('trainer/global_step', axis='index')\n",
    "                \n",
    "            if hist.empty:\n",
    "                continue\n",
    "\n",
    "            #hist[metric] = hist[metric].rolling(3).median() \n",
    "            if 1 >= ema_alpha and ema_alpha > 0: # ema smoothing for all but initial entries\n",
    "                hist[metric] = hist[metric].ewm(alpha=ema_alpha).mean()\n",
    "\n",
    "            if metric in hist.keys() and not hist[metric].empty:\n",
    "                hists.append(hist[metric].rename(run.name))\n",
    "            if xmetric in hist.keys() and not hist[xmetric].empty:\n",
    "                hists_xs.append(hist[xmetric].rename(run.name))\n",
    "        \n",
    "        # make one dataframe for this group\n",
    "        if len(hists) == 0:\n",
    "            print(f'Run {run.name} in {group_key} has no history with metric \\'{metric}\\'.')\n",
    "            continue\n",
    "        n_aggregates[f'{label}'] = len(hists)\n",
    "\n",
    "        hists = pd.concat(hists, axis='columns')\n",
    "        if len(hists_xs) > 0:\n",
    "            hists.index = max(hists_xs, key=len) # use longest xmetric as index\n",
    "\n",
    "        # aggregate metric accross runs in group to represent the distribution center\n",
    "        hists_center = None\n",
    "        if center == 'mean':\n",
    "            hists_center = hists.mean(axis=1, skipna=True)\n",
    "        if center == 'median':\n",
    "            hists_center = hists.median(axis=1, skipna=True)\n",
    "        if hists_center is not None:\n",
    "            ax.plot(hists.index, hists_center, color=color, label=label, **center_kwargs)\n",
    "\n",
    "        # aggregate metric accross runs in group to represent the distribution spread \n",
    "        hists_lower, hists_upper = None, None\n",
    "        if spread == 'minmax':\n",
    "            hists_lower = hists.min(axis=1, skipna=True)\n",
    "            hists_upper = hists.max(axis=1, skipna=True)\n",
    "        if spread == 'std' and center == 'mean':\n",
    "            hists_std = hists.std(axis=1, skipna=True).fillna(0.0)\n",
    "            hists_lower = hists_center - hists_std\n",
    "            hists_upper = hists_center + hists_std\n",
    "        if hists_lower is not None:\n",
    "            ax.fill_between(hists.index, hists_lower, hists_upper, color=color, **spread_kwargs)\n",
    "        elif spread == 'samples':\n",
    "            ax.plot(hists.index, hists, color=color, **spread_kwargs)\n",
    "\n",
    "        summary[group_key] = {'centers':hists_center, 'colors':color, 'labels':label}\n",
    "        if summarize is None:\n",
    "            continue # process next group\n",
    "\n",
    "        # summarize metric within run but ignore first ones\n",
    "        if summarize == 'max':\n",
    "            bests = hists.iloc[slice2summarize, :].max(axis=0, skipna=True)\n",
    "        elif summarize == 'min':\n",
    "            bests = hists.iloc[slice2summarize, :].min(axis=0, skipna=True)\n",
    "        elif summarize == 'first':\n",
    "            bests = hists.head(1)\n",
    "        elif summarize == 'last':\n",
    "            bests = hists.tail(1)\n",
    "        else:\n",
    "            raise ValueError('Unkown key for summarize.')\n",
    "\n",
    "        summary[group_key]['medians'] = bests.median(skipna=True)\n",
    "        summary[group_key]['means'] = bests.mean(skipna=True)\n",
    "        summary[group_key]['stds']  = bests.std(skipna=True) \n",
    "        summary[group_key]['mins']  = bests.min(skipna=True)\n",
    "        summary[group_key]['maxs']  = bests.max(skipna=True)\n",
    "          \n",
    "    print(f'aggregated: {n_aggregates}')\n",
    "    return pd.DataFrame.from_dict(summary, orient='index')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Norm and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step = 2500\n",
    "xmetric = 'trainer/global_step'\n",
    "metric = 'params/var(grad)'\n",
    "\n",
    "kwargs = dict(group_by='config.enc',\n",
    "                xmetric=xmetric,\n",
    "                scan_step=1, \n",
    "                max_step=max_step,\n",
    "                ema_alpha=1,\n",
    "                center_kwargs=dict(alpha=0.8, lw=0.2),\n",
    "                summarize='last',\n",
    "            )\n",
    "\n",
    "nrows, ncols = 1, 1\n",
    "@plt.rc_context(figsizes.icml2022_half(nrows=nrows, ncols=ncols, height_to_width_ratio=figsizes._GOLDEN_RATIO))\n",
    "def plot_gradvar(runs, filename):\n",
    "    f, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True)   \n",
    "\n",
    "    ax.set_ylabel('gradient variance trace')\n",
    "    for color, run in zip(cm.tab10.colors, runs):\n",
    "        plot_agg(runs=[run], metric=metric, colors=color, labels=[f'{run.config[\"enc\"]}: {run.config[\"s_mode\"]}'], ax=ax, **kwargs)\n",
    "\n",
    "\n",
    "    ax.legend(frameon=True)\n",
    "\n",
    "    ax.set_xlim(-max_step // 20, max_step + max_step // 20)\n",
    "    ax.set_yscale('log') \n",
    "    ax.set_xlabel('step')\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "runs = [ \n",
    "    api.run('safelix/DINO/runs/3sg5hiwn'), # vgg11 + head in supervised\n",
    "    api.run('safelix/DINO/runs/sl426j4i'), # resnet18 + head in supervised\n",
    "    api.run('safelix/DINO/runs/1omtevqy'), # vgg11 + head in distillation\n",
    "    api.run('safelix/DINO/runs/3ip3rj1c'), # resnet18 + head in distillation\n",
    "]\n",
    "plot_gradvar(runs, 'gradvar.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step = 2500\n",
    "xmetric = 'trainer/global_step'\n",
    "metrics = {'kl-divergence':'train/KL',\n",
    "           'gradient norm': ['params/norm(grad)', 'params/head/norm(grad)', 'params/enc/norm(grad)'],\n",
    "           'gradient variance trace' : ['params/var(grad)', 'params/head/var(grad)', 'params/enc/var(grad)'],\n",
    "           'distance from init': ['params/norm(stud - init)', 'params/head/norm(stud - init)', 'params/enc/norm(stud - init)'],\n",
    "           'linear probe vs rank' : ('probe/student', 'train/feat/embed/s_x.rank()')}\n",
    "\n",
    "colors = cm.tab10.colors\n",
    "kwargs = dict(group_by='config.enc',\n",
    "                xmetric=xmetric,\n",
    "                #colors=cm.viridis,\n",
    "                scan_step=1, \n",
    "                max_step=max_step,\n",
    "                ema_alpha=0.9,\n",
    "                center_kwargs=dict(alpha=0.8, lw=0.2),\n",
    "                summarize='last',\n",
    "            )\n",
    "\n",
    "nrows, ncols = len(metrics), 1\n",
    "@plt.rc_context(figsizes.icml2022_half(nrows=nrows, ncols=ncols, height_to_width_ratio=figsizes._GOLDEN_RATIO))\n",
    "def plot_early(run, filename):\n",
    "    f, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True)   \n",
    "\n",
    "    for idx, (name, metric) in  enumerate(metrics.items()):\n",
    "        ax[idx].set_ylabel(name)\n",
    "\n",
    "        if isinstance(metric, tuple) and len(metric) == 2:\n",
    "            twinax = ax[idx].twinx()\n",
    "            plot_agg(runs=[run], metric=metric[1], labels=[metric[1]], colors=[colors[1]], ax=twinax, **kwargs)       \n",
    "            plot_agg(runs=[run], metric=metric[0], labels=[metric[0]], colors=[colors[0]], ax=ax[idx], **kwargs)     \n",
    "            handles1, labels1 = ax[idx].get_legend_handles_labels() \n",
    "            handles2, labels2 = twinax.get_legend_handles_labels()\n",
    "            twinax.legend(handles1+handles2, labels1+labels2, frameon=True)\n",
    "            continue\n",
    "\n",
    "        elif isinstance(metric, list):\n",
    "            for color, submetric in zip(colors, metric):\n",
    "                plot_agg(runs=[run], metric=submetric, colors=color, labels=[submetric[7:]], ax=ax[idx], **kwargs)\n",
    "                ax[idx].legend(frameon=True)\n",
    "            continue\n",
    "\n",
    "        plot_agg(runs=[run], metric=metric, ax=ax[idx], **kwargs)\n",
    "        ax[idx].legend(frameon=True)\n",
    "\n",
    "\n",
    "    ax[0].set_xlim(-max_step // 20, max_step + max_step // 20)\n",
    "    ax[0].set_yscale('log') \n",
    "    ax[1].set_yscale('log') \n",
    "    ax[2].set_yscale('log') \n",
    "    ax[-1].set_xlabel('step')\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "run = api.run('safelix/DINO/runs/1omtevqy') # vgg11 + head in distillation\n",
    "plot_early(run, 'early-distillation-vgg11.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = api.run('safelix/DINO/runs/3sg5hiwn') # vgg11 + head in supervised\n",
    "plot_early(run, 'early-supervised-vgg11.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = api.run('safelix/DINO/runs/3ip3rj1c') # resnet18 + head in distillation\n",
    "plot_early(run, 'early-distillation-resnet18.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = api.run('safelix/DINO/runs/sl426j4i') # resnet18 + head in supervised\n",
    "plot_early(run, 'early-supervised-resnet18.pdf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BatchSizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmetric = 'trainer/global_step'\n",
    "metrics = {'kl-divergence':'train/KL', \n",
    "            'gradient norm':'params/norm(grad)', \n",
    "            'distance from init':'params/norm(stud - init)',\n",
    "            'linear probing':'probe/student'\n",
    "            }\n",
    "\n",
    "\n",
    "nrows, ncols = len(metrics), 1\n",
    "@plt.rc_context(figsizes.icml2022_half(nrows=nrows, ncols=ncols, height_to_width_ratio=figsizes._GOLDEN_RATIO))\n",
    "def plot_batchsize_enc(runs, enc, filename=None, ax=None, kwargs=dict()):\n",
    "\n",
    "    kwargs_defaults = dict(group_by='config.bs_train',\n",
    "                xmetric=xmetric,\n",
    "                colors=cm.viridis_r, \n",
    "                scan_step=1, \n",
    "                max_step=2500,\n",
    "                ema_alpha=1,\n",
    "                center_kwargs=dict(alpha=0.8, lw=0.2),\n",
    "                summarize='last',\n",
    "            )\n",
    "    kwargs_defaults.update(kwargs)\n",
    "    kwargs = kwargs_defaults\n",
    "\n",
    "\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True)\n",
    "    ax = ax if nrows > 1 else [ax]\n",
    "\n",
    "    for idx, (name, metric) in  enumerate(metrics.items()):\n",
    "        summary = plot_agg(runs=runs, metric=metric, filter={'enc':enc}, ax=ax[idx], **kwargs)\n",
    "        ax[idx].set_ylabel(name)\n",
    "        if name in ['kl-divergence', 'gradient norm']:\n",
    "            ax[idx].set_yscale('log') \n",
    "\n",
    "    if kwargs['max_step'] is not None:\n",
    "        ax[0].set_xlim(-kwargs['max_step'] // 20, kwargs['max_step'] + kwargs['max_step'] // 20)\n",
    "    \n",
    "    legendcols = 6\n",
    "    handles, labels = ax[0].get_legend_handles_labels()\n",
    "    labels = [elem for i in range(legendcols) for elem in labels[i::legendcols]]    # transpose\n",
    "    handles = [elem for i in range(legendcols) for elem in handles[i::legendcols]]  # transpose\n",
    "    ax[0].legend(handles, labels, frameon=True, loc='upper center', handlelength=1, columnspacing=1, ncols=legendcols)\n",
    "\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)\n",
    "        plt.show()\n",
    "\n",
    "#plot_batchsize_enc(runs, enc='vgg11', filename='batchsize-vgg11.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = api.sweep('safelix/DINO/sweeps/bn9nj3n2').runs\n",
    "runs_batchaccum = api.sweep('safelix/DINO/sweeps/0wwrnkaj').runs\n",
    "\n",
    "nrows, ncols = len(metrics), 2\n",
    "with plt.rc_context(figsizes.icml2022_full(nrows=nrows, ncols=ncols, height_to_width_ratio=figsizes._GOLDEN_RATIO)):\n",
    "    f, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey='row')\n",
    "    plot_batchsize_enc(runs, enc='vgg11', ax=[a[0] for a in ax])\n",
    "    plot_batchsize_enc(runs, enc='resnet18', ax=[a[1] for a in ax])\n",
    "\n",
    "    # plot full batch training\n",
    "    kwargs=dict(colors='red', labels=[runs_batchaccum[1].config['bs_train'] * 192]) # runs_batchaccum[0].config['batchaccum']\n",
    "    plot_batchsize_enc(runs_batchaccum, enc='vgg11', ax=[a[0] for a in ax], kwargs=kwargs)\n",
    "    plot_batchsize_enc(runs_batchaccum, enc='resnet18', ax=[a[1] for a in ax], kwargs=kwargs)\n",
    "\n",
    "    [a[1].set_ylabel('') for a in ax]\n",
    "    plt.savefig('batchsize.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = api.sweep('safelix/DINO/sweeps/bn9nj3n2').runs\n",
    "runs_batchaccum = api.sweep('safelix/DINO/sweeps/0wwrnkaj').runs\n",
    "\n",
    "metrics = {'kl-divergence':'train/KL', \n",
    "            #'gradient norm':'params/norm(grad)', \n",
    "            #'distance from init':'params/norm(stud - init)',\n",
    "            'linear probing':'probe/student'\n",
    "            }\n",
    "\n",
    "nrows, ncols = len(metrics), 2\n",
    "with plt.rc_context(figsizes.icml2022_full(nrows=nrows, ncols=ncols, height_to_width_ratio=figsizes._GOLDEN_RATIO)):\n",
    "    f, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey='row')\n",
    "    plot_batchsize_enc(runs, enc='vgg11', ax=[a[0] for a in ax])\n",
    "    #plot_batchsize_enc(runs, enc='resnet18', ax=[a[1] for a in ax])\n",
    "\n",
    "    # plot full batch training\n",
    "    kwargs=dict(colors='red', labels=[runs_batchaccum[1].config['bs_train'] * 192]) # runs_batchaccum[0].config['batchaccum']\n",
    "    plot_batchsize_enc(runs_batchaccum, enc='vgg11', ax=[a[0] for a in ax], kwargs=kwargs)\n",
    "    #plot_batchsize_enc(runs_batchaccum, enc='resnet18', ax=[a[1] for a in ax], kwargs=kwargs)\n",
    "\n",
    "    [a[1].set_ylabel('') for a in ax]\n",
    "    plt.savefig('batchsize-vgg11.small.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context(figsizes.icml2022_full()):\n",
    "    data = {'vgg11':{}, 'resnet18':{}}\n",
    "\n",
    "    for run in runs:\n",
    "        epochs = run.summary['epoch'] + 1\n",
    "        runtime_min = run.summary['_runtime'] / 60\n",
    "        runtime_hours = run.summary['_runtime'] / 60 / 60\n",
    "\n",
    "        data[run.config['enc']][run.config['bs_train']] = runtime_min / epochs\n",
    "\n",
    "    plt.plot(*zip(*sorted(data['vgg11'].items())), '-o', label='vgg11')\n",
    "    plt.plot(*zip(*sorted(data['resnet18'].items())), '-o', label='resnet18')\n",
    "    plt.ylim(0, 5)\n",
    "    plt.ylabel('minutes per epoch')\n",
    "    plt.xlabel('training batch size')\n",
    "    plt.legend()\n",
    "\n",
    "bs_train = 256\n",
    "n_epochs = 2500\n",
    "print(f'vgg11: {data[\"vgg11\"][bs_train]:.1f} min => {n_epochs} epochs in { n_epochs * data[\"vgg11\"][bs_train] / 60 / 24 :.1f} days ')\n",
    "print(f'resnet18: {data[\"resnet18\"][bs_train]:.1f} min => {n_epochs} epochs in { n_epochs * data[\"resnet18\"][bs_train] / 60 / 24  :.1f} days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = api.run('safelix/DINO/runs/wbmnl6y4').config # initinterp\n",
    "config1 = api.run('safelix/DINO/runs/1omtevqy').config # gradvar\n",
    "config2 = api.run('safelix/DINO/runs/7t70ov3c').config # batchsizes\n",
    "config3 = api.run('safelix/DINO/runs/gjynwffs').config # batchsizes accum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict2set(d):\n",
    "    return {('key', v) for k, v in d.items()}\n",
    "\n",
    "def dictdiff(A:dict, B:dict):\n",
    "    return {k:v for k,v in A.items() if k not in B or v != B[k]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD + Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmetric = 'trainer/global_step'\n",
    "metrics = {'kl-divergence':'train/KL', \n",
    "            'gradient norm':'params/norm(grad)', \n",
    "            'distance from init':'params/norm(stud - init)',\n",
    "            'linear probing':'probe/student'\n",
    "            }\n",
    "\n",
    "nrows, ncols = len(metrics), 1\n",
    "@plt.rc_context(figsizes.icml2022_half(nrows=nrows, ncols=ncols, height_to_width_ratio=figsizes._GOLDEN_RATIO))\n",
    "def plot_lr(runs, enc, normlayer=None, filename=None, ax=None, kwargs=dict()):\n",
    "\n",
    "    kwargs_defaults = dict(group_by='config.opt_lr',\n",
    "                xmetric=xmetric,\n",
    "                colors=cm.viridis_r,\n",
    "                scan_step=1, \n",
    "                max_step=2500,\n",
    "                ema_alpha=1,\n",
    "                center_kwargs=dict(alpha=0.8, lw=0.2),\n",
    "                summarize='last',\n",
    "            )\n",
    "    kwargs_defaults.update(kwargs)\n",
    "    kwargs = kwargs_defaults\n",
    "\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True)\n",
    "    ax = ax if nrows > 1 else [ax]\n",
    "\n",
    "    summary = dict()\n",
    "    for idx, (name, metric) in  enumerate(metrics.items()):\n",
    "        summary[metric] = plot_agg(runs=runs, metric=metric, filter={'config.enc':enc, 'config.enc_norm_layer':normlayer}, \n",
    "                                   ax=ax[idx], **kwargs)\n",
    "        ax[idx].set_ylabel(name)\n",
    "        if metric in ['train/KL', 'params/norm(grad)', 'train/MSE']:\n",
    "            ax[idx].set_yscale('log') \n",
    "\n",
    "    if kwargs['max_step'] is not None:\n",
    "        ax[0].set_xlim(-kwargs['max_step'] // 20, kwargs['max_step'] + kwargs['max_step'] // 20)\n",
    "    \n",
    "    legendcols = 5\n",
    "    handles, labels = ax[0].get_legend_handles_labels()\n",
    "    labels = [elem for i in range(legendcols) for elem in labels[i::legendcols]]    # transpose\n",
    "    handles = [elem for i in range(legendcols) for elem in handles[i::legendcols]]  # transpose\n",
    "    ax[0].legend(handles, labels, frameon=True, loc='upper center', handlelength=1, columnspacing=1, ncols=legendcols)\n",
    "\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)\n",
    "        plt.show()\n",
    "\n",
    "    return summary\n",
    "\n",
    "runs = api.sweep('safelix/DINO/runs/eg0tf2oo').runs # SGD LR Gridsearch (CE)\n",
    "plot_lr(runs, enc='vgg11', normlayer='Identity', filename='sgd-lr-ce-vgg11.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = api.sweep('safelix/DINO/runs/eg0tf2oo').runs # SGD LR Gridsearch (CE)\n",
    "\n",
    "nrows, ncols = len(metrics), 2\n",
    "with plt.rc_context(figsizes.icml2022_full(nrows=nrows, ncols=ncols, height_to_width_ratio=figsizes._GOLDEN_RATIO)):\n",
    "    f, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey='row')\n",
    "    plot_lr(runs, enc='vgg11', normlayer='Identity', ax=[a[0] for a in ax])\n",
    "    plot_lr(runs, enc='resnet18', normlayer='BatchNorm', ax=[a[1] for a in ax])\n",
    "    ax[0][0].set_ylim(None, 1e-3)\n",
    "    ax[2][0].set_ylim(-10, 200)\n",
    "\n",
    "    [a[1].set_ylabel('') for a in ax]\n",
    "    plt.savefig('sgd-lr-ce.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = api.sweep('safelix/DINO/runs/eg0tf2oo').runs # SGD LR Gridsearch (CE)\n",
    "\n",
    "metrics = {'kl-divergence':'train/KL', \n",
    "            #'gradient norm':'params/norm(grad)', \n",
    "            #'distance from init':'params/norm(stud - init)',\n",
    "            'linear probing':'probe/student'\n",
    "            }\n",
    "\n",
    "nrows, ncols = len(metrics), 2\n",
    "with plt.rc_context(figsizes.icml2022_full(nrows=nrows, ncols=ncols, height_to_width_ratio=figsizes._GOLDEN_RATIO)):\n",
    "    f, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey='row')\n",
    "    plot_lr(runs, enc='vgg11', normlayer='Identity', ax=[a[0] for a in ax])\n",
    "    plot_lr(runs, enc='resnet18', normlayer='BatchNorm', ax=[a[1] for a in ax])\n",
    "    ax[0][0].set_ylim(None, 1e-3)\n",
    "    #ax[2][0].set_ylim(-10, 200)\n",
    "\n",
    "    [a[1].set_ylabel('') for a in ax]\n",
    "    plt.savefig('sgd-lr-ce.small.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = api.sweep('safelix/DINO/runs/90k67dq4').runs # SGD LR Gridsearch (MSE)\n",
    "\n",
    "xmetric = 'trainer/global_step'\n",
    "metrics = {'mean squared error':'train/MSE', \n",
    "            'gradient norm':'params/norm(grad)', \n",
    "            'distance from init':'params/norm(stud - init)',\n",
    "            'linear probing':'probe/student'\n",
    "            }\n",
    "\n",
    "nrows, ncols = len(metrics), 2\n",
    "with plt.rc_context(figsizes.icml2022_full(nrows=nrows, ncols=ncols, height_to_width_ratio=figsizes._GOLDEN_RATIO)):\n",
    "    f, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey='row')\n",
    "    plot_lr(runs, enc='vgg11', normlayer='Identity', ax=[a[0] for a in ax])\n",
    "    plot_lr(runs, enc='resnet18', normlayer='BatchNorm', ax=[a[1] for a in ax])\n",
    "    ax[0][0].set_ylim(None, 1e0)\n",
    "    ax[2][0].set_ylim(-10, 200)\n",
    "\n",
    "    [a[1].set_ylabel('') for a in ax]\n",
    "    plt.savefig('sgd-lr-mse.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate large LR with Simplified Head "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR Range Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 1, 1\n",
    "@plt.rc_context(figsizes.icml2022_half(nrows=nrows, ncols=ncols, height_to_width_ratio=figsizes._GOLDEN_RATIO))\n",
    "def plot_rangetest(runs, labels=None, colors=None, filename=None, ax=None):\n",
    "\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots()\n",
    "\n",
    "    if isinstance(runs, wandb.apis.public.Run):\n",
    "        runs = [runs]\n",
    "\n",
    "    if isinstance(labels, str):\n",
    "        labels = [labels] * len(runs)\n",
    "\n",
    "    if isinstance(colors, (tuple, str, float)):\n",
    "        colors = [colors] * len(runs)\n",
    "\n",
    "    agg = pd.DataFrame()\n",
    "    for idx, run in enumerate(runs):\n",
    "        loss = run.config['loss']\n",
    "        loss = loss if  loss != 'CE' else 'KL' # replace CE -> KL\n",
    "        metric = f'train/{loss}' #\n",
    "\n",
    "\n",
    "        #plot_agg(runs=[run], metric=metric, xmetric='hparams/lr', ax=ax, **kwargs)\n",
    "        df = pd.DataFrame(run.scan_history(keys=[metric, 'hparams/lr']), dtype=float).set_index('hparams/lr')\n",
    "        \n",
    "        label = labels[idx] if labels and idx < len(labels) else metric\n",
    "        color = colors[idx] if colors and idx < len(colors) else None\n",
    "        ax.plot(df.index, df[metric], label=label, color=color)\n",
    "        \n",
    "        df = df.rename(columns={metric:run.name})\n",
    "        agg = pd.concat([agg, df], axis=1).sort_index()\n",
    "        \n",
    "\n",
    "    ax.set_xlabel('step size')\n",
    "    ax.set_xscale('log') \n",
    "\n",
    "    ax.set_ylabel('train loss')\n",
    "    ax.set_yscale('log') \n",
    "    ax.legend(loc='upper left')\n",
    "\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)\n",
    "        plt.show()\n",
    "\n",
    "    return agg\n",
    "\n",
    "nrows, ncols = 1, 1\n",
    "with plt.rc_context(figsizes.icml2022_half(nrows=nrows, ncols=ncols, height_to_width_ratio=figsizes._GOLDEN_RATIO)):\n",
    "    runs = api.sweep('safelix/DINO/sweeps/yjeg6huc').runs # KL vs MSE\n",
    "\n",
    "    agg = plot_rangetest(runs, filename='lrrangetest-kl-vs-mse.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "runs = api.sweep('safelix/DINO/runs/xduatpbk').runs # SGD LR Gridsearch: Linear Head, MSE\n",
    "runs_fn = api.sweep('safelix/DINO/runs/4cu7u7mo').runs # SGD LR Gridsearch: Linear Head, FN+MSE\n",
    "\n",
    "xmetric = 'trainer/global_step'\n",
    "metrics = {'mean squared error':'train/MSE', \n",
    "            #'gradient norm':'params/norm(grad)', \n",
    "            #'distance from init':'params/norm(stud - init)',\n",
    "            'linear probing':'probe/student'\n",
    "            }\n",
    "\n",
    "nrows, ncols = len(metrics), 2\n",
    "with plt.rc_context(figsizes.icml2022_full(nrows=nrows, ncols=ncols, height_to_width_ratio=figsizes._GOLDEN_RATIO)):\n",
    "    f, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey='row')\n",
    "    summary = plot_lr(runs, enc='vgg13', ax=[a[0] for a in ax], kwargs=dict(max_step=None, xmetric='epoch', colors=cm.viridis_r))\n",
    "    summary_fn = plot_lr(runs_fn, enc='vgg13', ax=[a[1] for a in ax], kwargs=dict(max_step=None, xmetric='epoch', colors=cm.inferno_r))\n",
    "    ax[0][0].set_ylim(None, 1e0)\n",
    "    #ax[2][0].set_ylim(-10, 200)\n",
    "\n",
    "    #[a[1].set_ylabel('') for a in ax]\n",
    "    plt.savefig('sgd-lr-linhead-mse.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = next(iter(summary.values()))\n",
    "summary_fn = next(iter(summary_fn.values()))\n",
    "\n",
    "colors = {idx: summary['colors'][idx] for idx in summary.index if not isinstance(idx, str)}\n",
    "colors_fn = {idx: summary_fn['colors'][idx] for idx in summary_fn.index if not isinstance(idx, str)}\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "nrows, ncols = 1, 1\n",
    "with plt.rc_context(figsizes.icml2022_half(nrows=nrows, ncols=ncols, height_to_width_ratio=figsizes._GOLDEN_RATIO)):\n",
    "    runs = api.sweep('safelix/DINO/sweeps/lsy74rit').runs # FN vs no FN\n",
    "    run = api.run('safelix/DINO/runs/iprry987')\n",
    "    run_fn = api.run('safelix/DINO/runs/9wxlksbt')\n",
    "\n",
    "\n",
    "    f, ax = plt.subplots(nrows, ncols, sharex=True, sharey=True)\n",
    "    if isinstance(ax, matplotlib.axes.Axes):\n",
    "        ax = (ax, ax)\n",
    "    agg = plot_rangetest(run, labels='MSE', colors=tuple(cm.viridis.colors[160]), ax=ax[0])   \n",
    "    agg_fn = plot_rangetest(run_fn, labels='NMSE', colors=tuple(cm.inferno.colors[160]), ax=ax[1])\n",
    "    \n",
    "    ymin, ymax = ax[0].get_ylim()\n",
    "    xs = np.array(list(colors.keys()))\n",
    "    ys = np.interp(xs, agg.index, agg.values.squeeze())\n",
    "\n",
    "    ax[0].annotate('$\\\\frac{2}{L}$', (xs[0],ys[0]), xytext=(-1, 6), textcoords='offset pixels', fontsize=7)\n",
    "    #ax[0].scatter(xs[0], ys[0], marker='|', s=10, c=list(colors.values())[0], zorder=10)\n",
    "    ax[0].scatter(xs[0:], ys[0:], marker='x', s=10, c=list(colors.values())[0:], zorder=10)\n",
    "    #for x, y, c in zip(xs, ys, colors.values()):\n",
    "        #ax[0].vlines(x, ymin, ymax, color=c)\n",
    "        #ax[0].annotate(x, (x,y), xytext=(0, 20), textcoords='offset pixels', fontsize=5)\n",
    "\n",
    "    xs = np.array(list(colors_fn.keys()))\n",
    "    ys = np.interp(xs, agg_fn.index, agg_fn.values.squeeze())\n",
    "\n",
    "    ax[1].annotate('$\\\\frac{2}{L}$', (xs[0],ys[0]), xytext=(-1, -8), textcoords='offset pixels', fontsize=7)\n",
    "    #ax[1].scatter(xs[0], ys[0], marker='|', s=10, c=list(colors_fn.values())[0], zorder=10)\n",
    "    ax[1].scatter(xs[0:], ys[0:], marker='x', s=10, c=list(colors_fn.values())[0:], zorder=10)\n",
    "    #for lr, color in colors_fn.items():\n",
    "    #    ax[1].vlines(lr, ymin, ymax, color=color)\n",
    "\n",
    "    ax[0].set_xlim(10**-3, 10**6)\n",
    "    ax[0].set_ylim(None, 10**10)\n",
    "\n",
    "    plt.savefig('lrrangetest-mse-vs-nmse.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Experiment: MSE vs ND-MSE vs N-MSE for different LRs and schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "print(255*np.array(cm.tab10(3)))\n",
    "cm.tab10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from colorsys import hls_to_rgb\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "\n",
    "def make_colorscale(h=223, dh=0, l=0.33, dl=0., s=1., ds=0, beta=1, num=256):\n",
    "    h = np.linspace(h-dh, h+dh, num=num) / 360\n",
    "    l = (l-dl) + (dl+dl) * np.linspace(0., 1., num=num) ** beta \n",
    "    s = (s-ds) + (ds+ds) * np.linspace(0., 1., num=num) ** beta\n",
    "    hls = np.stack([h, np.flip(l), s], axis=1) # flip luminosity to start with bright\n",
    "    rgb = np.apply_along_axis((lambda row: hls_to_rgb(*row)), axis=1, arr=hls)\n",
    "    return ListedColormap(colors=rgb)\n",
    "\n",
    "make_colorscale(h=223, l=0.33, dh=60, dl=0.20, beta=5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue = hls_to_rgb(h=223/360,l=0.33, s=1)\n",
    "bluescale = make_colorscale(h=223, l=0.33, dl=0.2, beta=1.5)\n",
    "bluescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = hls_to_rgb(h=(223 + 120)/360, l=0.33, s=1)\n",
    "redscale = make_colorscale(h=223 + 120, l=0.33, dl=0.2, beta=1.5)\n",
    "redscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green = hls_to_rgb(h=(223 - 120)/360, l=0.25, s=1)\n",
    "greenscale = make_colorscale(h=223 - 120, l=0.22, dl=0.15, beta=1.5)\n",
    "greenscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR Range Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rangetest(labels, colors, group_keys, colored_dots={}, ax=None):\n",
    "    runs = api.sweep('DINO/sweeps/hyfq2un6').runs\n",
    "\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots()\n",
    "\n",
    "    summary = plot_agg(runs, group_by='config.l2bot_cfg', metric='train/loss', xmetric='hparams/lr', \n",
    "                    labels=labels, colors=colors, group_keys=group_keys, center='median', spread='minmax', \n",
    "                    center_kwargs=dict(alpha=0.6), spread_kwargs=dict(alpha=0.15), scan_step=1, ax=ax)\n",
    "    \n",
    "    for group_key, xs_colors in colored_dots.items():\n",
    "        line = summary['centers'][group_key]\n",
    "        xs = np.array(list(xs_colors.keys()))\n",
    "        ys = np.interp(xs, line.index, line.values.squeeze())\n",
    "        ax.scatter(xs, ys, marker='x', s=10, c=list(xs_colors.values()), zorder=10)\n",
    "\n",
    "    ax.set_xlabel('step size')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(1e-3, 1e6)\n",
    "\n",
    "    ax.set_ylabel('train loss')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(1e-16, 1e6)\n",
    "    ax.legend(loc='upper left')\n",
    "    return ax\n",
    "\n",
    "labels = ['MSE', 'ND-MSE', 'N-MSE']\n",
    "colors = [blue, red, green]\n",
    "group_keys = ['-/-/-/-/lb/-', '-/-/-/-/lb/fnd', '-/-/-/-/lb/fn']\n",
    "ax = plot_rangetest(labels=labels, colors=colors, group_keys=group_keys)\n",
    "plt.savefig('lrrangetest.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from dinopl.scheduling import Schedule, ConstSched, LinWarmup, CosWarmup\n",
    "\n",
    "def make_colors(cmap, xs):\n",
    "    norm = BoundaryNorm(sorted(xs), cmap.N, extend='max')\n",
    "    cmapper = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    return {x:cmapper.to_rgba(x) for x in xs}\n",
    "\n",
    "def run2sortkey(run):\n",
    "    sortkey1 = cfgs.index(run.config['l2bot_cfg'])\n",
    "    sortkey2 = scheds.index(type(Schedule.parse(run.config['opt_lr'])))\n",
    "    sortkey3 = run.summary['hparams/lr']\n",
    "    return sortkey1, sortkey2, sortkey3\n",
    "\n",
    "\n",
    "# load and prepare hyperparameters and \n",
    "sweep = api.sweep('safelix/DINO/sweeps/deoormth')\n",
    "lrs = sweep.config['parameters']['opt_lr']['values']\n",
    "lrs = [lr for lr in lrs if isinstance(lr, (int, float))]\n",
    "\n",
    "scheds = [ConstSched, LinWarmup, CosWarmup]\n",
    "sched2ls = {sched:ls for sched, ls in zip(scheds, ['-','--', '-.'])}\n",
    "\n",
    "losses = ['MSE', 'ND-MSE', 'N-MSE']\n",
    "cfgs = ['-/-/-/-/lb/-', '-/-/-/-/lb/fnd', '-/-/-/-/lb/fn']\n",
    "cfg2loss = {cfg:loss for cfg, loss in zip(cfgs, losses)}\n",
    "cfg2color = {cfg:scale for cfg, scale in zip(cfgs, [blue, red, green])}\n",
    "cfg2cmap = {cfg:scale for cfg, scale in zip(cfgs, [bluescale, redscale, greenscale])}\n",
    "cfglr2color = {cfg:make_colors(cfg2cmap[cfg], lrs) for cfg in cfgs}\n",
    "\n",
    "runs = list(sorted(sweep.runs, key=run2sortkey))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_keys = cfgs\n",
    "labels = [cfg2loss[cfg] for cfg in cfgs]\n",
    "colors = [cfg2color[cfg] for cfg in cfgs]\n",
    "ax = plot_rangetest(group_keys=group_keys, labels=labels, colors=colors, colored_dots=cfglr2color)\n",
    "plt.savefig('lrrangetest-dots.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from dinopl.scheduling import Schedule, ConstSched, LinWarmup, CosWarmup\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "for run in sorted(sweep.runs, key=run2sortkey):\n",
    "    sched = type(Schedule.parse(run.config['opt_lr']))\n",
    "\n",
    "    if run.config['l2bot_cfg'] != '-/-/-/-/lb/fn':\n",
    "        continue\n",
    "\n",
    "    if sched not in [LinWarmup, CosWarmup]:\n",
    "        continue\n",
    "    \n",
    "    ls = sched2ls[sched]\n",
    "    plot_agg([run], group_by='summary.hparams/lr', metric='hparams/lr', xmetric='epoch', colors=['gray'], labels=[None],\n",
    "                center='mean', spread=None, center_kwargs=dict(alpha=0.6, ls=ls), scan_step=100, ax=ax)\n",
    "\n",
    "for sched in [LinWarmup, CosWarmup]:\n",
    "    ax.plot(0, 0, label=sched.__name__, color='gray', ls=sched2ls[sched])\n",
    "ax.legend(loc='lower right', frameon=True)\n",
    "\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('stepsize')\n",
    "ax.set_ylim(-0.05 * lrs[-3], 1.05 * lrs[-3])\n",
    "\n",
    "plt.savefig('lrs.pdf')\n",
    "\n",
    "clear_output()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gridsearch_epochs(filter_lrs=lrs, filter_losses=['MSE', 'N-MSE', 'ND-MSE'], \n",
    "                    filter_sched=(ConstSched, LinWarmup, CosWarmup), pseudolabels=[], ax=None):\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots()\n",
    "    \n",
    "    summary = {}\n",
    "    for run in sorted(sweep.runs, key=run2sortkey):\n",
    "        lr = run.summary['hparams/lr']\n",
    "        sched = type(Schedule.parse(run.config['opt_lr']))\n",
    "        cfg = run.config['l2bot_cfg']\n",
    "        loss = cfg2loss[cfg]\n",
    "\n",
    "        if lr not in filter_lrs:\n",
    "            continue\n",
    "        if loss not in filter_losses:\n",
    "            continue\n",
    "        if sched not in filter_sched:\n",
    "            continue\n",
    "        \n",
    "        label = run.name if len(pseudolabels)==0 else None # make pseudolabels\n",
    "        color, ls = cfglr2color[cfg][lr], sched2ls[sched]\n",
    "        out = plot_agg([run], group_by='summary.hparams/lr', metric='probe/student', xmetric='epoch', colors=[color], labels=[label],\n",
    "                    center='mean', spread=None, center_kwargs=dict(alpha=0.6, ls=ls), slice2summarize=slice(10, None), ax=ax)\n",
    "\n",
    "        if cfg not in summary.keys():\n",
    "            summary[cfg] = {}\n",
    "        if sched not in summary[cfg].keys():\n",
    "            summary[cfg][sched] = {}\n",
    "        if lr in out['means'].index:\n",
    "            summary[cfg][sched][lr] = np.nan_to_num(out['means'][lr], nan=0.1) # nan => diverged => 0.1 probing accuracy\n",
    "\n",
    "    for kwargs in pseudolabels:\n",
    "        ax.plot(0,0,**kwargs)\n",
    "\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('probing accuracy')\n",
    "    ax.set_ylim(0.05, 0.55)\n",
    "    return summary, ax\n",
    "\n",
    "plot_gridsearch_epochs()\n",
    "#plt.legend(loc='upper left', frameon=True)\n",
    "#plt.savefig(f'lrgridsearch.pdf')\n",
    "\n",
    "clear_output()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def plot_gridsearch_summary(summary, ax=None):\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots()\n",
    "\n",
    "    for cfg in summary.keys():\n",
    "        for sched in summary[cfg].keys():\n",
    "            xs = list(summary[cfg][sched].keys())\n",
    "            ys = list(summary[cfg][sched].values())\n",
    "            ax.plot(xs, ys, color=cfg2color[cfg], ls=sched2ls[sched], alpha=0.6)\n",
    "            ax.scatter(xs, ys, color=[cfglr2color[cfg][x] for x in xs], alpha=0.6, s=8)\n",
    "    \n",
    "    ax.set_xlabel('step size')\n",
    "    ax.set_xscale('log')\n",
    "    xoffset = (lrs[-1]/lrs[0])**0.05\n",
    "    ax.set_xlim(lrs[0]/xoffset, lrs[-1]*xoffset)\n",
    "\n",
    "    ax.set_ylabel('probing accuracy')\n",
    "    ax.set_ylim(0.05, 0.55)\n",
    "    return ax\n",
    "\n",
    "\n",
    "summary, ax = plot_gridsearch_epochs()\n",
    "plt.close()\n",
    "clear_output()\n",
    "\n",
    "plot_gridsearch_summary(summary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def plot_gridsearch(filter_lrs=lrs, filter_losses=losses, filter_sched=scheds, pseudolabels=[], summary=None):\n",
    "    \n",
    "    nrows, ncols = (1, 2) if summary else (1, 1)    \n",
    "    figsize = figsizes.icml2022_full if summary else figsizes.icml2022_half\n",
    "    with plt.rc_context(figsize(nrows=nrows, ncols=ncols, height_to_width_ratio=figsizes._GOLDEN_RATIO)):\n",
    "        f, ax = plt.subplots(nrows, ncols, sharex=False, sharey=True)\n",
    "        ax = [ax] if ncols==1 else ax\n",
    "\n",
    "        # plot gridsearch epochs into ax[0]\n",
    "        new_summary, _ = plot_gridsearch_epochs(filter_lrs, filter_losses, filter_sched, pseudolabels, ax=ax[0])\n",
    "\n",
    "        if summary == True:             # use new summary if was true\n",
    "            summary = new_summary\n",
    "        elif isinstance(summary, dict): # merge if summary was dict\n",
    "            for cfg in new_summary.keys():\n",
    "                for sched in new_summary[cfg].keys():\n",
    "                    for lr in new_summary[cfg][sched].keys():\n",
    "                        if cfg not in summary.keys():\n",
    "                            summary[cfg] = {}\n",
    "                        if sched not in summary[cfg].keys():\n",
    "                            summary[cfg][sched] = {}\n",
    "                        summary[cfg][sched][lr] = new_summary[cfg][sched][lr]\n",
    "\n",
    "        if isinstance(summary, dict): # plot gridsearch summary if is dict \n",
    "            plot_gridsearch_summary(summary, ax=ax[1])\n",
    "\n",
    "    return summary, ax\n",
    "\n",
    "pseudolabels = [dict(label=cfg2loss[cfg], color=cfg2color[cfg]) for cfg in cfgs]\n",
    "pseudolabels += [dict(label=sched.__name__, color='gray', ls=ls) for sched, ls in sched2ls.items()]\n",
    "\n",
    "summary, ax = plot_gridsearch(summary=True, pseudolabels=pseudolabels)\n",
    "ax[0].legend(loc='lower right', frameon=True, ncols=2)\n",
    "plt.savefig(f'lrgridsearch.pdf')\n",
    "clear_output()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "pseudolabels = [dict(label=cfg2loss[cfg], color=cfg2color[cfg]) for cfg in cfgs]\n",
    "\n",
    "summary = True\n",
    "for idx, lr in enumerate(lrs):\n",
    "    plt.close()\n",
    "    summary, ax = plot_gridsearch(filter_lrs=lrs[:idx+1], filter_sched=[ConstSched], pseudolabels=pseudolabels, summary=summary)\n",
    "    ax[0].text(0.05, 0.95, f'lr={lr:.1f}', ha='left', va='top', transform=ax[0].transAxes)\n",
    "    ax[0].legend(loc='lower right', frameon=True, ncols=1)\n",
    "    plt.savefig(f'lrgridsearch-constsched-lr={int(lr):06d}.pdf')\n",
    "    clear_output()\n",
    "plt.show()\n",
    "\n",
    "#!pdfunite lrgridsearch-constsched-lr=*.pdf lrgridsearch-constsched-lr.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "pseudolabels = [dict(label=cfg2loss[cfg], color=cfg2color[cfg]) for cfg in cfgs]\n",
    "pseudolabels += [dict(label=sched.__name__, color='gray', ls=ls) for sched, ls in sched2ls.items()]\n",
    "\n",
    "summary = True\n",
    "for idx, lr in enumerate(lrs):\n",
    "    plt.close()\n",
    "    summary, ax = plot_gridsearch(filter_lrs=[lr], pseudolabels=pseudolabels, summary=summary)\n",
    "    ax[0].text(0.05, 0.95, f'lr={lr:.1f}', ha='left', va='top', transform=ax[0].transAxes)\n",
    "    ax[0].legend(loc='lower right', frameon=True, ncols=2)\n",
    "    plt.savefig(f'lrgridsearch-lr={int(lr):06d}.pdf')\n",
    "    clear_output()\n",
    "plt.show()\n",
    "\n",
    "#!pdfunite lrgridsearch-lr=*.pdf lrgridsearch-lr.pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "pseudolabels = [dict(label=cfg2loss[cfg], color=cfg2color[cfg]) for cfg in cfgs]\n",
    "\n",
    "for idx, (sched, ls) in enumerate(sched2ls.items()):\n",
    "    plt.close()\n",
    "    _, ax = plot_gridsearch(filter_sched=[sched], summary=True,\n",
    "                            pseudolabels=pseudolabels+[dict(label=sched.__name__, color='gray', ls=ls)])\n",
    "    ax[0].legend(loc='lower right', frameon=True, ncols=1)\n",
    "    plt.savefig(f'lrgridsearch-{sched.__name__.lower()}.pdf')\n",
    "    clear_output()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
